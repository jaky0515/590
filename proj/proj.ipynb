{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Modules - include all modules here\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from pprint import pprint\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation, Reshape, Lambda, LSTM, Dropout, Conv2D, MaxPooling2D, Embedding\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.merge import add, concatenate\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "List of classes\n",
    "\"\"\"\n",
    "\n",
    "# DataElement Class\n",
    "class DataElement:\n",
    "    \"\"\"\n",
    "    This object contains variables for a single data\n",
    "    @author: Kevin Jang (kj460)\n",
    "    \"\"\"\n",
    "    label = None        # label (tag number) of this plate\n",
    "    height = None       # height of this plate\n",
    "    width = None        # width of this plate\n",
    "    label_length = None # number of characters in this plate's label\n",
    "    img = None          # parsed image\n",
    "    tags = []           # data tags\n",
    "    \n",
    "    def __init__( self, label, height, width, label_length, img, tags ):\n",
    "        \"\"\"\n",
    "        Constructor for this class\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        self.label = label\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.label_length = label_length\n",
    "        self.img = img\n",
    "        self.tags = tags\n",
    "    \n",
    "    def __str__( self ):\n",
    "        \"\"\"\n",
    "        Returns the value of each variable for this class\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        return \"\\t** Values:\\n\\t\\t* label : {}\\n\\t\\t* height : {}\\n\\t\\t* width : {}\\n\\t\\t* label_length = {}\\n\\t\\t* img = {}\\n\\t\\t* tags = {}\\n\".format( self.label, self.height, self.width, self.label_length, self.img, self.tags )\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        return self.__str__()\n",
    "\n",
    "# DataSet Class\n",
    "class DataSet:\n",
    "    \"\"\"\n",
    "    This object contains the list of DataElement for a single dataset\n",
    "    @author: Kevin Jang (kj460)\n",
    "    \"\"\"\n",
    "    data_path = None  # path of the directory that contains data files\n",
    "    data = {}         # list of DataElement\n",
    "    num_redundant = 0 # number of redundant data\n",
    "    num_missing = 0   # number of missing data\n",
    "    num_noisy = 0     # number of noisy data\n",
    "\n",
    "    def __init__( self, data_path ):\n",
    "        \"\"\"\n",
    "        Constructor for this class\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "    \n",
    "    def __str__( self ):\n",
    "        \"\"\"\n",
    "        Returns the state of each DataElement in the data list\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        string = \"\"\n",
    "        for label, data_elem in self.data.items():\n",
    "            string += str( data_elem )\n",
    "        return string\n",
    "    \n",
    "    def valid_json( self, json_data ):\n",
    "        \"\"\"\n",
    "        Returns True if a given json_data is valid else return False\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        if 'description' not in json_data or 'size' not in json_data or 'height' not in json_data[ 'size'] or 'width' not in json_data[ 'size' ] or 'tags' not in json_data or len( json_data[ 'tags' ] ) == 0:\n",
    "            self.num_missing += 1\n",
    "            return False\n",
    "        elif len( json_data[ 'description' ] ) != 8 or int( json_data[ 'size' ][ 'width' ] ) != 152 or int( json_data[ 'size' ][ 'height' ] ) != 34:\n",
    "            self.num_noisy += 1\n",
    "            return False\n",
    "        elif json_data[ 'description' ] in self.data.keys():\n",
    "            self.num_redundant += 1\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    def build_dataset( self, num_files ):\n",
    "        \"\"\"\n",
    "        Reads data files and create DataElement for each data file and include it in the data list\n",
    "        @author: Kevin Jang (kj460)\n",
    "        @params:\n",
    "            num_files - number of data files to be read; set this to 'None' to read all the files\n",
    "        \"\"\"\n",
    "        ann_path = self.data_path + '/ann'\n",
    "        img_path = self.data_path + '/img'\n",
    "        count = 0\n",
    "        for file in os.listdir( ann_path ):\n",
    "            if num_files != None and count >= num_files:\n",
    "                # stop reading\n",
    "                break\n",
    "            # file validation\n",
    "            if '.json' not in file:\n",
    "                continue\n",
    "            # process JSON file\n",
    "            json_file = open( ann_path + '/' + file )\n",
    "            json_data = json.load( json_file )\n",
    "            # data validation\n",
    "            if not self.valid_json( json_data ):\n",
    "                continue\n",
    "            # create a new DataElement\n",
    "            data_elem = DataElement( json_data[ 'description' ],\n",
    "                                   json_data[ 'size' ][ 'height' ],\n",
    "                                   json_data[ 'size' ][ 'width' ],\n",
    "                                   len( json_data[ 'description' ] ),\n",
    "                                   None,\n",
    "                                   json_data[ 'tags' ] )\n",
    "            # process PNG file\n",
    "            img_file = cv2.imread( img_path + '/' + ( file.split( '.json' )[ 0 ] ) + '.png' )\n",
    "            img_file = cv2.cvtColor( img_file, cv2.COLOR_BGR2GRAY )\n",
    "            img_file = cv2.resize( img_file, ( data_elem.width, data_elem.height ) )\n",
    "            img_file = img_file.astype( np.float32 ) / 255\n",
    "            # add a new DataElement to the list\n",
    "            data_elem.img = img_file\n",
    "            self.data[ data_elem.label ] = data_elem\n",
    "            count += 1\n",
    "            \n",
    "# TrainTestDataSet Class\n",
    "class TrainTestDataSet:\n",
    "    \"\"\"\n",
    "    This object contains DataSet for training and testing\n",
    "    @author: Kevin Jang (kj460)\n",
    "    \"\"\"\n",
    "    train_data_path = None # path of the directory that contains training data files\n",
    "    test_data_path = None  # path of the directory that contains testing data files\n",
    "    train_dataset = None   # training DataSet object\n",
    "    test_dataset = None    # testing DataSet object\n",
    "    \n",
    "    def __init__( self, train_data_path, test_data_path ):\n",
    "        \"\"\"\n",
    "        Constructor for this class\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        self.train_data_path = train_data_path\n",
    "        self.test_data_path = test_data_path\n",
    "        \n",
    "    def __str__( self ):\n",
    "        \"\"\"\n",
    "        Returns the string that contains information about training and testing dataset\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        return '*** Training Set ***\\n' + str( self.train_dataset ) + '\\n*** Testing Set ***\\n' + str( self.test_dataset )\n",
    "    \n",
    "    def build_train_test_dataset( self ):\n",
    "        \"\"\"\n",
    "        Builds training and testing DataSet\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        self.train_dataset = DataSet( self.train_data_path )\n",
    "        self.train_dataset.build_dataset( None )\n",
    "        self.test_dataset = DataSet( self.test_data_path )\n",
    "        self.test_dataset.build_dataset( None )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataValidator Class\n",
    "class DataValidator:\n",
    "    '''\n",
    "    Validator class to check the data cleanliness\n",
    "    @author: Kevin Jang (kj460)\n",
    "    '''\n",
    "    train_test_dataset = None\n",
    "    \n",
    "    def __init__( self, train_test_dataset ):\n",
    "        \"\"\"\n",
    "        Constructor for this class\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        self.train_test_dataset = train_test_dataset\n",
    "        \n",
    "    def __str__( self ):\n",
    "        \"\"\"\n",
    "        Returns the string that contains information about validation on both training and testing dataset\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        str = '*** DataSet Validation ***\\n'\n",
    "        str += '\\t** Number of Redundant Data\\n'\n",
    "        str += '\\t\\t* Training DataSet : {}\\n'.format( self.train_test_dataset.train_dataset.num_redundant )\n",
    "        str += '\\t\\t* Testing DataSet : {}\\n'.format( self.train_test_dataset.test_dataset.num_redundant )\n",
    "        str += '\\t** Number of Missing Data\\n'\n",
    "        str += '\\t\\t* Training DataSet : {}\\n'.format( self.train_test_dataset.train_dataset.num_missing )\n",
    "        str += '\\t\\t* Testing DataSet : {}\\n'.format( self.train_test_dataset.test_dataset.num_missing )\n",
    "        str += '\\t** Number of Noisy Data\\n'\n",
    "        str += '\\t\\t* Training DataSet : {}\\n'.format( self.train_test_dataset.train_dataset.num_noisy )\n",
    "        str += '\\t\\t* Testing DataSet : {}\\n'.format( self.train_test_dataset.test_dataset.num_noisy )\n",
    "        return str\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directiory that contains the data files\n",
    "train_data_path = 'data/ANPR_OCR__train'\n",
    "test_data_path = 'data/ANPR_OCR__test'\n",
    "\n",
    "# create TrainTestDataSet\n",
    "train_test_dataset = TrainTestDataSet( train_data_path, test_data_path )\n",
    "train_test_dataset.build_train_test_dataset()\n",
    "\n",
    "# print the dataset\n",
    "# print( str( train_test_dataset ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** DataSet Validation ***\n",
      "\t** Number of Redundant Data\n",
      "\t\t* Training DataSet : 0\n",
      "\t\t* Testing DataSet : 0\n",
      "\t** Number of Missing Data\n",
      "\t\t* Training DataSet : 0\n",
      "\t\t* Testing DataSet : 0\n",
      "\t** Number of Noisy Data\n",
      "\t\t* Training DataSet : 0\n",
      "\t\t* Testing DataSet : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the cleanliness of the dataset\n",
    "data_validator = DataValidator( train_test_dataset )\n",
    "print( str ( data_validator ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11382\n",
      "2315\n"
     ]
    }
   ],
   "source": [
    "training_set = {}\n",
    "random.random()\n",
    "for key, value in train_test_dataset.train_dataset.data.items():\n",
    "    rand = random.randint(1, 5)\n",
    "    if rand is 3:\n",
    "        training_set[key] = value\n",
    "print(len(train_test_dataset.train_dataset.data))\n",
    "print(len(training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set = set()\n",
    "for key, value in train_test_dataset.train_dataset.data.items():\n",
    "    for c in key:\n",
    "        char_set.add(c)\n",
    "\n",
    "char_list = sorted(list(char_set))\n",
    "height = 34\n",
    "width = 152\n",
    "\n",
    "def label_to_indices(label):\n",
    "    return list(map(lambda x: char_list.index(x), label))\n",
    "\n",
    "def indices_to_label(indices):\n",
    "    return ''.join(list(map(lambda x: char_list[int(x)], indices)))\n",
    "\n",
    "def decoding_to_label(y):\n",
    "    result = []\n",
    "    for i in range(y.shape[0]):\n",
    "        prev = -1\n",
    "        max_index = 0\n",
    "        s = ''\n",
    "        for j in range(2, len(y[0])):\n",
    "            for k in range(len(y[0][0])):\n",
    "                if y[i][j][k] > y[i][j][max_index]:\n",
    "                    max_index = k\n",
    "            if max_index is not prev and max_index < len(char_list):\n",
    "                s = s + char_list[max_index]\n",
    "            prev = max_index\n",
    "        result.append(s)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgLabelGenerator:\n",
    "    def __init__(self, ds, batch_size, down_factor):\n",
    "        self.label_len = 8\n",
    "        self.data_len = len(ds)\n",
    "        self.indices = list(range(self.data_len))\n",
    "        self.cur_index = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.down_factor = down_factor\n",
    "        self.imgs = np.zeros((self.data_len, height, width))\n",
    "        self.labels = []\n",
    "        for i, (key, value) in enumerate(ds.items()):\n",
    "            self.labels.append(key)\n",
    "            self.imgs[i, :, :] = value.img\n",
    "        \n",
    "    def next_element(self):\n",
    "        if self.data_len-1 > self.cur_index:\n",
    "            self.cur_index = self.cur_index + 1\n",
    "        else:\n",
    "            random.shuffle(self.indices)\n",
    "            self.cur_index = 0\n",
    "        position = self.indices[self.cur_index]\n",
    "        return (self.labels[position], self.imgs[position])\n",
    "\n",
    "    def next_batch(self):\n",
    "        while True:\n",
    "            X = np.ones([self.batch_size, width, height, 1])\n",
    "            y = np.ones([self.batch_size, self.label_len])\n",
    "            input_arr = np.ones((self.batch_size, 1)) * (width // self.down_factor - 2)\n",
    "            label_arr = np.zeros((self.batch_size, 1))\n",
    "            for i in range(self.batch_size):\n",
    "                label, img = self.next_element()\n",
    "                img = np.expand_dims(img.T, -1)\n",
    "                X[i] = img\n",
    "                y[i] = label_to_indices(label)\n",
    "                label_arr[i] = len(label)\n",
    "            \n",
    "            inputs = {'input': X, 'labels': y, 'input_arr': input_arr, 'label_arr': label_arr}\n",
    "            outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "            yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 152, 34, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 152, 34, 32)  320         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_225 (MaxPooling2D (None, 76, 17, 32)   0           conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 76, 17, 32)   9248        max_pooling2d_225[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_226 (MaxPooling2D (None, 38, 8, 32)    0           conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_99 (Reshape)            (None, 38, 256)      0           max_pooling2d_226[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_179 (Dense)               (None, 38, 32)       8224        reshape_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_116 (LSTM)                 (None, 38, 128)      82432       dense_179[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_117 (LSTM)                 (None, 38, 128)      82432       dense_179[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 38, 128)      0           lstm_116[0][0]                   \n",
      "                                                                 lstm_117[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_118 (LSTM)                 (None, 38, 128)      131584      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_119 (LSTM)                 (None, 38, 128)      131584      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 38, 256)      0           lstm_118[0][0]                   \n",
      "                                                                 lstm_119[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_180 (Dense)               (None, 38, 23)       5911        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sf_result (Activation)          (None, 38, 23)       0           dense_180[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 451,735\n",
      "Trainable params: 451,735\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 152, 34, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 152, 34, 32)  320         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_225 (MaxPooling2D (None, 76, 17, 32)   0           conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 76, 17, 32)   9248        max_pooling2d_225[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_226 (MaxPooling2D (None, 38, 8, 32)    0           conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_99 (Reshape)            (None, 38, 256)      0           max_pooling2d_226[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_179 (Dense)               (None, 38, 32)       8224        reshape_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_116 (LSTM)                 (None, 38, 128)      82432       dense_179[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_117 (LSTM)                 (None, 38, 128)      82432       dense_179[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 38, 128)      0           lstm_116[0][0]                   \n",
      "                                                                 lstm_117[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_118 (LSTM)                 (None, 38, 128)      131584      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_119 (LSTM)                 (None, 38, 128)      131584      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 38, 256)      0           lstm_118[0][0]                   \n",
      "                                                                 lstm_119[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_180 (Dense)               (None, 38, 23)       5911        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sf_result (Activation)          (None, 38, 23)       0           dense_180[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "labels (InputLayer)             (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_arr (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_arr (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           sf_result[0][0]                  \n",
      "                                                                 labels[0][0]                     \n",
      "                                                                 input_arr[0][0]                  \n",
      "                                                                 label_arr[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 451,735\n",
      "Trainable params: 451,735\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_arr, label_arr = args\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_arr, label_arr)\n",
    "\n",
    "ilg_train = ImgLabelGenerator(train_test_dataset.train_dataset.data, 128, 4)\n",
    "#ilg_train = ImgLabelGenerator(training_set, 8, 4)\n",
    "\n",
    "input_data = Input(name='input', shape=(width, height, 1), dtype='float32')\n",
    "x = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(input_data)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Reshape(target_shape=(width // 4, (height // 4) * 32))(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "\n",
    "lstm_11 = LSTM(256, return_sequences=True, kernel_initializer='he_normal')(x)\n",
    "lstm_12 = LSTM(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal')(x)\n",
    "lstm1_merged = add([lstm_11, lstm_12])\n",
    "lstm_21 = LSTM(256, return_sequences=True, kernel_initializer='he_normal')(lstm1_merged)\n",
    "lstm_22 = LSTM(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal')(lstm1_merged)\n",
    "x = Dense(len(char_list)+1, kernel_initializer='he_normal')(concatenate([lstm_21, lstm_22]))\n",
    "#x = Dense(len(char_list)+1, kernel_initializer='he_normal')(lstm_2)\n",
    "\n",
    "y_pred = Activation('softmax', name='sf_result')(x)\n",
    "Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "labels = Input(name='labels', shape=[ilg_train.label_len], dtype='float32')\n",
    "\n",
    "input_arr = Input(name='input_arr', shape=[1], dtype='int64')\n",
    "label_arr = Input(name='label_arr', shape=[1], dtype='int64')\n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_arr, label_arr])\n",
    "model = Model(inputs=[input_data, labels, input_arr, label_arr], outputs=loss_out)\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2315/2315 [==============================] - 301s 130ms/step - loss: 5.9780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xccefc1b38>"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=ilg_train.next_batch(), steps_per_epoch=ilg_train.data_len, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11382\n",
      "2198\n"
     ]
    }
   ],
   "source": [
    "testing_set = {}\n",
    "random.random()\n",
    "for key, value in train_test_dataset.test_dataset.data.items():\n",
    "    rand = random.randint(1, 5)\n",
    "    if rand is 3:\n",
    "        testing_set[key] = value\n",
    "print(len(train_test_dataset.test_dataset.data))\n",
    "print(len(testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "256\n",
      "384\n",
      "512\n",
      "640\n",
      "768\n",
      "896\n",
      "1024\n",
      "1151\n",
      "1279\n",
      "1407\n",
      "1534\n",
      "1662\n",
      "1790\n",
      "1918\n",
      "2046\n",
      "2173\n",
      "2301\n",
      "2429\n",
      "2556\n",
      "2684\n",
      "2812\n",
      "2940\n",
      "3068\n",
      "3196\n",
      "3324\n",
      "3452\n",
      "3580\n",
      "3708\n",
      "3836\n",
      "3964\n",
      "4091\n",
      "4219\n",
      "4347\n",
      "4475\n",
      "4603\n",
      "4731\n",
      "4859\n",
      "4987\n",
      "5115\n",
      "5243\n",
      "5371\n",
      "5499\n",
      "5627\n",
      "5755\n",
      "5883\n",
      "6011\n",
      "6138\n",
      "6266\n",
      "6394\n",
      "6522\n",
      "6650\n",
      "6778\n",
      "6906\n",
      "7034\n",
      "7162\n",
      "7290\n",
      "7417\n",
      "7545\n",
      "7673\n",
      "7801\n",
      "7929\n",
      "8057\n",
      "8185\n",
      "8313\n",
      "8441\n",
      "8569\n",
      "8697\n",
      "8825\n",
      "8953\n",
      "9081\n",
      "9209\n",
      "9337\n",
      "9465\n",
      "9593\n",
      "9720\n",
      "9848\n",
      "9976\n",
      "10104\n",
      "10232\n",
      "10360\n",
      "10488\n",
      "10616\n",
      "10744\n",
      "10872\n",
      "11000\n",
      "11128\n",
      "11256\n",
      "The accuracy rate is: 0.9992971358285011\n"
     ]
    }
   ],
   "source": [
    "ilg_test = ImgLabelGenerator(train_test_dataset.test_dataset.data, 128, 4)\n",
    "#ilg_test = ImgLabelGenerator(testing_set, 8, 4)\n",
    "\n",
    "total_len = len(train_test_dataset.test_dataset.data)\n",
    "correct = 0\n",
    "count = 0\n",
    "\n",
    "for input_set, output_set in ilg_test.next_batch():\n",
    "    output_value = sess.run(model.get_layer(name='sf_result').output, feed_dict={model.get_layer(name='input').input : input_set['input']})\n",
    "    pred_labels = decoding_to_label(output_value)\n",
    "\n",
    "    for i, label in enumerate(input_set['labels']):\n",
    "        label = indices_to_label(label)\n",
    "        if label == pred_labels[i]:\n",
    "            correct = correct + 1\n",
    "        count = count + 1\n",
    "        if count == total_len:\n",
    "            break\n",
    "    \n",
    "    if count == total_len:\n",
    "        break\n",
    "    print(correct)\n",
    "    '''\n",
    "    for i in range(bs):\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        ax1 = plt.Subplot(fig, outer[0])\n",
    "        fig.add_subplot(ax1)\n",
    "        ax2 = plt.Subplot(fig, outer[1])\n",
    "        fig.add_subplot(ax2)\n",
    "        print('The predicted plate label:', pred_labels[i])\n",
    "        print('Ture value of the plate label:', label_list[i])\n",
    "        img = X[i][:, :, 0].T\n",
    "        ax1.set_title('Input img')\n",
    "        ax1.imshow(img, cmap='gray')\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax2.set_title('Activations')\n",
    "        ax2.imshow(net_out_value[i].T, cmap='binary', interpolation='nearest')\n",
    "        ax2.set_yticks(list(range(len(char_list) + 1)))\n",
    "        ax2.set_yticklabels(char_list + ['blank'])\n",
    "        ax2.grid(False)\n",
    "        for h in np.arange(-0.5, len(char_list) + 1 + 0.5, 1):\n",
    "            ax2.axhline(h, linestyle='-', color='k', alpha=0.5, linewidth=1)\n",
    "        \n",
    "        plt.show()\n",
    "    break\n",
    "    '''\n",
    "\n",
    "print(\"The accuracy rate is: \" + str(correct / total_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

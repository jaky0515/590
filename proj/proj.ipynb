{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Modules - include all modules here\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "List of classes\n",
    "\"\"\"\n",
    "\n",
    "# DataElement Class\n",
    "class DataElement:\n",
    "    \"\"\"\n",
    "    This object contains variables for a single data\n",
    "    @author: Kevin Jang (kj460)\n",
    "    \"\"\"\n",
    "    label = None        # label (tag number) of this plate\n",
    "    height = None       # height of this plate\n",
    "    width = None        # width of this plate\n",
    "    label_length = None # number of characters in this plate's label\n",
    "    img = None          # parsed image\n",
    "    tags = []           # data tags\n",
    "    \n",
    "    def __init__( self, label, height, width, label_length, img, tags ):\n",
    "        \"\"\"\n",
    "        Constructor for this class\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        self.label = label\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.label_length = label_length\n",
    "        self.img = img\n",
    "        self.tags = tags\n",
    "    \n",
    "    def __str__( self ):\n",
    "        \"\"\"\n",
    "        Returns the value of each variable for this class\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        return \"\\t** Values:\\n\\t\\t* label : {}\\n\\t\\t* height : {}\\n\\t\\t* width : {}\\n\\t\\t* label_length = {}\\n\\t\\t* img = {}\\n\\t\\t* tags = {}\\n\".format( self.label, self.height, self.width, self.label_length, self.img, self.tags )\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        return self.__str__()\n",
    "\n",
    "# DataSet Class\n",
    "class DataSet:\n",
    "    \"\"\"\n",
    "    This object contains the list of DataElement for a single dataset\n",
    "    @author: Kevin Jang (kj460)\n",
    "    \"\"\"\n",
    "    data_path = None  # path of the directory that contains data files\n",
    "    data = {}         # list of DataElement\n",
    "    num_redundant = 0 # number of redundant data\n",
    "    num_missing = 0   # number of missing data\n",
    "    num_noisy = 0     # number of noisy data\n",
    "\n",
    "    def __init__( self, data_path ):\n",
    "        \"\"\"\n",
    "        Constructor for this class\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "    \n",
    "    def __str__( self ):\n",
    "        \"\"\"\n",
    "        Returns the state of each DataElement in the data list\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        string = \"\"\n",
    "        for label, data_elem in self.data.items():\n",
    "            string += str( data_elem )\n",
    "        return string\n",
    "    \n",
    "    def valid_json( self, json_data ):\n",
    "        \"\"\"\n",
    "        Returns True if a given json_data is valid else return False\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        if 'description' not in json_data or 'size' not in json_data or 'height' not in json_data[ 'size'] or 'width' not in json_data[ 'size' ] or 'tags' not in json_data or len( json_data[ 'tags' ] ) == 0:\n",
    "            self.num_missing += 1\n",
    "            return False\n",
    "        elif len( json_data[ 'description' ] ) != 8 or int( json_data[ 'size' ][ 'width' ] ) != 152 or int( json_data[ 'size' ][ 'height' ] ) != 34:\n",
    "            self.num_noisy += 1\n",
    "            return False\n",
    "        elif json_data[ 'description' ] in self.data.keys():\n",
    "            self.num_redundant += 1\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    def build_dataset( self, num_files ):\n",
    "        \"\"\"\n",
    "        Reads data files and create DataElement for each data file and include it in the data list\n",
    "        @author: Kevin Jang (kj460)\n",
    "        @params:\n",
    "            num_files - number of data files to be read; set this to 'None' to read all the files\n",
    "        \"\"\"\n",
    "        ann_path = self.data_path + '/ann'\n",
    "        img_path = self.data_path + '/img'\n",
    "        count = 0\n",
    "        for file in os.listdir( ann_path ):\n",
    "            if num_files != None and count >= num_files:\n",
    "                # stop reading\n",
    "                break\n",
    "            # file validation\n",
    "            if '.json' not in file:\n",
    "                continue\n",
    "            # process JSON file\n",
    "            json_file = open( ann_path + '/' + file )\n",
    "            json_data = json.load( json_file )\n",
    "            # data validation\n",
    "            if not self.valid_json( json_data ):\n",
    "                continue\n",
    "            # create a new DataElement\n",
    "            data_elem = DataElement( json_data[ 'description' ],\n",
    "                                   json_data[ 'size' ][ 'height' ],\n",
    "                                   json_data[ 'size' ][ 'width' ],\n",
    "                                   len( json_data[ 'description' ] ),\n",
    "                                   None,\n",
    "                                   json_data[ 'tags' ] )\n",
    "            # process PNG file\n",
    "            img_file = cv2.imread( img_path + '/' + ( file.split( '.json' )[ 0 ] ) + '.png' )\n",
    "            img_file = cv2.cvtColor( img_file, cv2.COLOR_BGR2GRAY )\n",
    "            img_file = cv2.resize( img_file, ( data_elem.width, data_elem.height ) )\n",
    "            img_file = img_file.astype( np.float32 ) / 255\n",
    "            # add a new DataElement to the list\n",
    "            data_elem.img = img_file\n",
    "            self.data[ data_elem.label ] = data_elem\n",
    "            count += 1\n",
    "            \n",
    "# TrainTestDataSet Class\n",
    "class TrainTestDataSet:\n",
    "    \"\"\"\n",
    "    This object contains DataSet for training and testing\n",
    "    @author: Kevin Jang (kj460)\n",
    "    \"\"\"\n",
    "    train_data_path = None # path of the directory that contains training data files\n",
    "    test_data_path = None  # path of the directory that contains testing data files\n",
    "    train_dataset = None   # training DataSet object\n",
    "    test_dataset = None    # testing DataSet object\n",
    "    \n",
    "    def __init__( self, train_data_path, test_data_path ):\n",
    "        \"\"\"\n",
    "        Constructor for this class\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        self.train_data_path = train_data_path\n",
    "        self.test_data_path = test_data_path\n",
    "        \n",
    "    def __str__( self ):\n",
    "        \"\"\"\n",
    "        Returns the string that contains information about training and testing dataset\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        return '*** Training Set ***\\n' + str( self.train_dataset ) + '\\n*** Testing Set ***\\n' + str( self.test_dataset )\n",
    "    \n",
    "    def build_train_test_dataset( self ):\n",
    "        \"\"\"\n",
    "        Builds training and testing DataSet\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        self.train_dataset = DataSet( self.train_data_path )\n",
    "        self.train_dataset.build_dataset( None )\n",
    "        self.test_dataset = DataSet( self.test_data_path )\n",
    "        self.test_dataset.build_dataset( None )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataValidator Class\n",
    "class DataValidator:\n",
    "    '''\n",
    "    Validator class to check the data cleanliness\n",
    "    @author: Kevin Jang (kj460)\n",
    "    '''\n",
    "    train_test_dataset = None\n",
    "    \n",
    "    def __init__( self, train_test_dataset ):\n",
    "        \"\"\"\n",
    "        Constructor for this class\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        self.train_test_dataset = train_test_dataset\n",
    "        \n",
    "    def __str__( self ):\n",
    "        \"\"\"\n",
    "        Returns the string that contains information about validation on both training and testing dataset\n",
    "        @author: Kevin Jang (kj460)\n",
    "        \"\"\"\n",
    "        str = '*** DataSet Validation ***\\n'\n",
    "        str += '\\t** Number of Redundant Data\\n'\n",
    "        str += '\\t\\t* Training DataSet : {}\\n'.format( self.train_test_dataset.train_dataset.num_redundant )\n",
    "        str += '\\t\\t* Testing DataSet : {}\\n'.format( self.train_test_dataset.test_dataset.num_redundant )\n",
    "        str += '\\t** Number of Missing Data\\n'\n",
    "        str += '\\t\\t* Training DataSet : {}\\n'.format( self.train_test_dataset.train_dataset.num_missing )\n",
    "        str += '\\t\\t* Testing DataSet : {}\\n'.format( self.train_test_dataset.test_dataset.num_missing )\n",
    "        str += '\\t** Number of Noisy Data\\n'\n",
    "        str += '\\t\\t* Training DataSet : {}\\n'.format( self.train_test_dataset.train_dataset.num_noisy )\n",
    "        str += '\\t\\t* Testing DataSet : {}\\n'.format( self.train_test_dataset.test_dataset.num_noisy )\n",
    "        return str\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directiory that contains the data files\n",
    "train_data_path = 'data/ANPR_OCR__train'\n",
    "test_data_path = 'data/ANPR_OCR__test'\n",
    "\n",
    "# create TrainTestDataSet\n",
    "train_test_dataset = TrainTestDataSet( train_data_path, test_data_path )\n",
    "train_test_dataset.build_train_test_dataset()\n",
    "\n",
    "# print the dataset\n",
    "# print( str( train_test_dataset ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** DataSet Validation ***\n",
      "\t** Number of Redundant Data\n",
      "\t\t* Training DataSet : 0\n",
      "\t\t* Testing DataSet : 0\n",
      "\t** Number of Missing Data\n",
      "\t\t* Training DataSet : 0\n",
      "\t\t* Testing DataSet : 0\n",
      "\t** Number of Noisy Data\n",
      "\t\t* Training DataSet : 0\n",
      "\t\t* Testing DataSet : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the cleanliness of the dataset\n",
    "data_validator = DataValidator( train_test_dataset )\n",
    "print( str ( data_validator ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
